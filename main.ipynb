{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2 \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "IMG_SIZE = 150\n",
    "TRAIN_DIR = '/home/hai/Desktop/Cat&Dog/all/train'\n",
    "TEST_DIR = '/home/hai/Desktop/Cat&Dog/all/test'\n",
    "\n",
    "\n",
    "train_data_dir = '/home/hai/Desktop/Cat&Dog/all/train/'\n",
    "nb_train_samples = 2000\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]\n",
    "    if word_label == 'cat' : return [1,0]\n",
    "    elif word_label == 'dog' : return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img), np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    #np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "    shuffle(testing_data)\n",
    "    #np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:20<00:00, 1195.21it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3),input_shape = input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer ='rmsprop', metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-1000]\n",
    "test = train_data[-1000:]\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "24000/24000 [==============================] - 26s 1ms/step - loss: 7.9530 - acc: 0.5016 - val_loss: 8.5441 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.46700, saving model to weights-improvement-01-0.47.hdf5\n",
      "Epoch 2/50\n",
      "24000/24000 [==============================] - 24s 988us/step - loss: 7.9434 - acc: 0.5011 - val_loss: 8.5441 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.46700\n",
      "Epoch 3/50\n",
      "24000/24000 [==============================] - 23s 976us/step - loss: 7.9479 - acc: 0.5006 - val_loss: 8.5441 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.46700\n",
      "Epoch 4/50\n",
      "24000/24000 [==============================] - 24s 983us/step - loss: 7.9343 - acc: 0.5017 - val_loss: 8.5441 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.46700\n",
      "Epoch 5/50\n",
      "24000/24000 [==============================] - 23s 977us/step - loss: 7.9371 - acc: 0.5011 - val_loss: 8.5441 - val_acc: 0.4670\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.46700\n",
      "Epoch 6/50\n",
      "24000/24000 [==============================] - 23s 973us/step - loss: 4.7860 - acc: 0.5304 - val_loss: 0.6668 - val_acc: 0.6305\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.46700 to 0.63050, saving model to weights-improvement-06-0.63.hdf5\n",
      "Epoch 7/50\n",
      "24000/24000 [==============================] - 23s 967us/step - loss: 0.6321 - acc: 0.6763 - val_loss: 0.5503 - val_acc: 0.7620\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.63050 to 0.76200, saving model to weights-improvement-07-0.76.hdf5\n",
      "Epoch 8/50\n",
      "24000/24000 [==============================] - 23s 968us/step - loss: 0.5776 - acc: 0.7310 - val_loss: 0.5246 - val_acc: 0.7605\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.76200\n",
      "Epoch 9/50\n",
      "24000/24000 [==============================] - 23s 975us/step - loss: 0.5423 - acc: 0.7524 - val_loss: 0.5156 - val_acc: 0.7585\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.76200\n",
      "Epoch 10/50\n",
      "24000/24000 [==============================] - 23s 972us/step - loss: 0.5170 - acc: 0.7695 - val_loss: 0.4740 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.76200 to 0.79250, saving model to weights-improvement-10-0.79.hdf5\n",
      "Epoch 11/50\n",
      "24000/24000 [==============================] - 23s 969us/step - loss: 0.4979 - acc: 0.7769 - val_loss: 0.4626 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.79250 to 0.82300, saving model to weights-improvement-11-0.82.hdf5\n",
      "Epoch 12/50\n",
      "24000/24000 [==============================] - 23s 969us/step - loss: 0.4796 - acc: 0.7885 - val_loss: 0.5159 - val_acc: 0.7745\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.82300\n",
      "Epoch 13/50\n",
      "24000/24000 [==============================] - 23s 977us/step - loss: 0.4824 - acc: 0.7867 - val_loss: 0.4726 - val_acc: 0.8030\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.82300\n",
      "Epoch 14/50\n",
      "24000/24000 [==============================] - 23s 976us/step - loss: 0.4779 - acc: 0.7921 - val_loss: 0.4739 - val_acc: 0.8145\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.82300\n",
      "Epoch 15/50\n",
      " 8832/24000 [==========>...................] - ETA: 14s - loss: 0.4782 - acc: 0.7956"
     ]
    }
   ],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "callbacks = [ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')]\n",
    "\n",
    "model.fit(x = np.array(X), y = np.array(Y), batch_size = batch_size, epochs = epochs,callbacks = callbacks, validation_data = (np.array(test_x), np.array(test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = process_test_data()\n",
    "with open('submission_file.csv','w') as f:\n",
    "    f.write('id,label\\n')\n",
    "            \n",
    "with open('submission_file.csv','a') as f:\n",
    "    for data in tqdm(test_data):\n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "        model_out = model.predict([data])[0]\n",
    "        f.write('{},{}\\n'.format(img_num,model_out[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
